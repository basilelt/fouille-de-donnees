# Notes de Cours : Introduction aux Réseaux de Neurones

Ce cours de fouille de données est dédié aux réseaux de neurones, couvrant leur historique, les principes fondamentaux du Perceptron, l'algorithme d'apprentissage, un exercice pratique et une introduction au Deep Learning.

## 1. Historique des Réseaux de Neurones

- **Années 1960**
  - Rosenblatt propose le Perceptron, un classifieur binaire.
  - Minsky et Papert mettent en évidence l'incapacité des Perceptrons simples à résoudre des problèmes non linéaires (ex: problème XOR).
  - "AI Winter": Période de perte de confiance due à cette limitation.

- **1974**
  - Werbos propose l'algorithme de Rétropropagation du gradient (Backpropagation), permettant de résoudre les problèmes non linéaires en utilisant des réseaux multicouches.
  - L'algorithme est réutilisé et popularisé par Mel, Hinton et Williams pour l'entraînement des réseaux multicouches.

- **Années 1990**
  - Apparition des CNN (Convolutional Neural Networks) pour la classification d'images, proposés par Yann LeCun.
  - Yann LeCun reçoit le Prix Turing (équivalent Nobel en informatique) pour ses travaux sur les CNN.

## 2. Le Perceptron : Bases et Fonctionnement

- **Définition**: Un neurone est une unité de calcul qui prend des entrées, effectue un calcul et renvoie une sortie.
- **Entrées**: n entrées (x1 à xn) et un biais x0 toujours égal à 1.
- **Paramètres**: Les poids (weights) W0 à WN sont les valeurs apprises pendant l'entraînement.
- **Calcul de la sortie (version simple)**:
  1. Calcul d'une somme pondérée des entrées et des poids (∑(xi * Wi)).
  2. Cette somme est passée à une fonction d'activation qui calcule la sortie finale du neurone.
- **Limitation**: Le perceptron de base modélise des décisions linéaires et ne peut pas résoudre des problèmes non linéaires.
- **Représentation schématique**: Entrées (x0...xn) -> Poids (W0...Wn) -> Somme pondérée -> Fonction d'activation -> Sortie.

## 3. Algorithme d'Apprentissage du Perceptron : Correction par Erreur

- **Principe**: Ajuster les poids du réseau pour maximiser le taux de bonnes réponses.
- **Étapes**:
  1. Initialiser le perceptron et ses poids à des valeurs arbitraires.
  2. Pour chaque exemple d'entraînement:
     - Présenter l'exemple au réseau.
     - Calculer la sortie.
     - Comparer la sortie avec la classe attendue.
     - Si la classification est incorrecte, ajuster les poids.
  3. L'algorithme s'arrête lorsque tous les exemples sont correctement classés et qu'aucun changement de poids n'est nécessaire (stabilité).
- **Formule de mise à jour des poids**:
  $W_{\text{nouveau}} = W_{\text{précédent}} + \eta \times (C - O) \times X_{\text{entrée}}$
- **η**: Taux d'apprentissage (non explicitement mentionné mais implicite dans le coefficient multiplicateur, souvent appelé alpha).
- **C**: Classe attendue (cible).
- **O**: Sortie calculée par le réseau.
- **X_entrée**: Valeur de l'entrée correspondante.
- **Si C = O, (C - O) est 0, donc les poids ne sont pas modifiés.**
- **Note**: Modifier les poids peut altérer la classification correcte d'exemples précédemment bien classés, nécessitant plusieurs passes sur l'ensemble des exemples.

## 4. Exercice Pratique : Apprentissage du "OU Booléen"

- **Objectif**: Entraîner un perceptron à apprendre la fonction logique OU.
- **Entrées**: x0=1 (biais), x1 et x2 (binaires: 0 ou 1).
- **Sortie attendue**: x1 OU x2.
- **Processus**:
  1. Initialiser les poids arbitrairement (ex: 0, -1, 1 pour W0, W1, W2).
  2. Parcourir séquentiellement les exemples du tableau d'entraînement.
  3. Pour chaque exemple, calculer la sortie et mettre à jour les poids si nécessaire.
  4. Repasser sur l'ensemble des exemples si des poids ont été modifiés, jusqu'à ce que les poids soient stables et que tous les exemples soient bien classés.
- **Résultat stable (ex)**: Poids finaux de 0, 1, 1 pour W0, W1, W2 (pour le ou booléen).

## 5. Deep Learning (Apprentissage Profond)

- **Définition**: Terme "à la mode" désignant des réseaux de neurones profonds, c'est-à-dire des réseaux avec plusieurs couches de neurones.
- **Caractéristiques**: Contiennent de nombreuses couches et un très grand nombre de paramètres (parfois des milliards dans les réseaux modernes).
- **Principe fondamental**: Le même que celui du perceptron simple (unités de calcul qui prennent, calculent et transmettent de l'information), mais avec une complexité accrue due à la profondeur.
- **Succès**: Capacité à entraîner des réseaux multicouches pour apprendre des décisions non linéaires complexes.
- **Exemples d'architectures notables**:
  - **LeNet-5 (1998)**:
    - Conçu pour la reconnaissance de chiffres manuscrits (dataset MNIST).
    - Contenait environ 60 000 paramètres.
    - Structure typique: couches de convolution, couches de sous-échantillonnage, couche entièrement connectée, distribution de probabilité en sortie.
  - **AlexNet (2012)**:
    - A révolutionné la classification d'images sur le benchmark ImageNet.
    - Contenait environ 60 millions de paramètres.
  - **Inception (2014)**:
    - Proposé pour ImageNet.
    - Particularité: Utilise des convolutions de tailles différentes au même niveau de couche pour capturer l'information à diverses échelles.
  - **VGG16 (2015)**:
    - Contenait environ 138 millions de paramètres.
- **Évolution et facteurs clés**:
  - Augmentation constante de la profondeur des réseaux et du nombre de paramètres.
  - Performance accrue du matériel (GPU): plus de puissance de calcul et de mémoire, permettant d'entraîner des modèles de plus en plus complexes et profonds.
- **Architectures plus récentes**:
  - **Transformers (2017)**: "Attention Is All You Need" (papier de recherche). Une architecture particulière qui a marqué une évolution importante.
- **Le principe d'entraînement (ajustement des poids pour corriger les erreurs) reste le même, même si les architectures internes et les "briques" des réseaux deviennent plus complexes.**

## 6. Conclusion Générale

- Le concept d'entraînement des perceptrons, c'est-à-dire ajuster les poids pour corriger les erreurs, demeure la base fondamentale de tous les réseaux de neurones, y compris les plus profonds et complexes actuels.
- L'apprentissage profond applique ce principe pour entraîner des réseaux multicouches capables de résoudre des problèmes complexes et non linéaires.
- Ces techniques sont utilisées dans de nombreuses applications modernes (ex: architectures type Transformers).