## KNN (k-Nearest Neighbors)

- Versatile Algorithm: Suitable for classification, regression and recommendation
- Simple Yet Powerful: Effective with appropriate feature engineering
- Distance Metrics: Choice of metric crucial for performance
- Challenges: Computationally intensive; may struggle in high-dimensional spaces
- Advanced Techniques: Kernelized k-NN, ensembles, etc.
- Practical Considerations: Feature scaling, missing data, selecting optimal 'k'
- Real-world Applications: Used in medical diagnosis, financial forecasting, etc.

What type of learning is k-Nearest Neighbors (k-NN) classified under?
Instance-based learning


Which distance metric is commonly used in the k-NN algorithm?
Euclidean Distance


What is a primary disadvantage of the k-NN algorithm?
High computational cost


What is the effect of choosing a small value of 'k' in k-NN?
Sensitive to noise


Which technique is used to ensure features contribute equally to distance computation in k-NN?
Feature scaling


Which type of voting in k-NN assigns more influence to closer neighbors?
Weighted voting


What does 'lazy learning' refer to in the context of k-NN?
No model building during training


What is the main purpose of one-hot encoding in k-NN?
Handle categorical features


Which method helps in choosing an optimal value for 'k' in k-NN?
Cross-validation


What is a real-world application of the k-NN algorithm?
Medical diagnosis


What is a key challenge of using k-NN with large datasets?
High computational complexity


In which scenario is weighted voting particularly useful in k-NN?
When closer neighbors should have more influence


What preprocessing step is critical for k-NN when dealing with features of varying scales?
Normalization


What is a common strategy to avoid ties in k-NN binary classification problems?
Choose an odd value for 'k'